{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bfa583-eb43-4f58-82e7-72d0f440fe5c",
   "metadata": {},
   "source": [
    "# ID2214/FID3214 Fx Assignment\n",
    "Abyel Tesfay, Abyel@kth.se\n",
    "\n",
    "### Instructions\n",
    "The following jupyter notebook contains solutions to a set of tasks in the form of simulations and tests, comments explaining the solutions and any assumptions made. This notebook was written with the purpose of completing the assignments below and receive the grade E. Each assignment consists of an explanation, a form of simulation (or results from it) and a conclusion. Below the assignmets you will find instructions to recreate the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcdc886-6387-4dc8-8b43-88ccd4e69c3d",
   "metadata": {},
   "source": [
    "## Load packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034bfd19-b51b-4366-9d9e-4ebaeaeb636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9f06f-4481-4625-be63-b20a4b63d9f5",
   "metadata": {},
   "source": [
    "## 1a. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb8478-e1f7-44d5-b3cb-73b31b2339d1",
   "metadata": {},
   "source": [
    "It depends on the outcome of the models generated from the hyper-parameter settings and the algorithm used. The performance of the best-performing model is biased on how the given dataset is randomly split into two samples. Therefore the performance (accuracy) of the best-performing model might be too optimistic, its good score is dependent on the current sample that was randomly generated. For this observation i performed the following steps.\n",
    "- I chose the dataset \"healthcare-dataset-stroke-data.csv\" which is classified with binary labels\n",
    "- I prepared two equally sized samples using randomized sampling\n",
    "- For modelling i used RandomForest with the hyper-parameters 'n_estimators', 'criterion' and 'max_features', the best performing model was picked by the highest average accuracy from a ten-fold cross-validation\n",
    "- For performance estimation i trained a model with the best configuration and a baseline model, using the first half as training set. I then tested both models using the second half as a test set.\n",
    "\n",
    "Using the hyper-paramters 'n_estimators'= [1,10,50,100,250], criterion ['gini', 'entropy'] and 'max_features' = [1,2,...,10] i received the following results:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4c9511f-90b3-4c9a-a081-30d1cea75f53",
   "metadata": {},
   "source": [
    "Modelling & cross-validation:\n",
    "    Hyper-parameters is better\n",
    "    best hyper-parameters:  {'trees': 50, 'critera': 'gini', 'features': 2}\n",
    "    hyper-parameters score:  0.954205\n",
    "    base model score:  0.953421\n",
    "    no. hyper-parameters better than baseline model:  41\n",
    "\n",
    "Evaluation:\n",
    "    baseline model is better or equal\n",
    "    Accuracy hyper-par: 0.947945 , trees: 50 , criterion: gini , features: 2\n",
    "    Accuracy baseline:  0.948337 , trees 100 , criterion: gini , features: auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a235396-af20-4cb0-836d-cf301d91db32",
   "metadata": {},
   "source": [
    "The results show that even if the best-performing configuration for hyper-parameters (and algorithm) outperforms the baseline model in the first half of data, the baseline model may still *outperform the best-performing configuration* in the second half. I also checked the amount models that performed better than the baseline during modelling, this was to see if a majority of them could outperform on the first half of data. If this were true, then the best performing configuration would be *more likely to outperform* the baseline on the second half of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61099f76-2709-48ca-b7ea-cf6f6cd73bcc",
   "metadata": {},
   "source": [
    "## 1b. Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d129a-67cd-446a-a6b1-3f3a9bda5321",
   "metadata": {},
   "source": [
    "Assuming that the model was trained on a imbalanced training set which contains instances that are not present in the test set, we should expect a **lower accuracy but a similar AUC** when evaluating the model on the class-balanced set. The reason is that the model was trained on a imbalanced set where the majority class is frequent. When evaluated on a class-balanced test set (which has a lower frequency of the majority class) the acuracy will decrease. For the AUC however we will see a similar performance. The AUC only measures the probability of the model to rank an instance with the correct label ahead of instances with the wrong label. A lower accuracy will not affect this metric. \n",
    "\n",
    "The following steps were taken with two different datasets\n",
    "- Select a data set for the task\n",
    "- Split the dataset into two halves, one training set and one 'sampling' set \n",
    "- Use the sampling set to create the following test sets described in 1b:\n",
    "    - An imbalanced test set in which the majority class is 4 times more frequent than the minority class\n",
    "    - A class-balanced test set (has fewer instances than the above data set however)\n",
    "- Perform data preparation on the training set: filtering and imputation\n",
    "- Generate and train two identical models using a selected algorithm e.g RandomForest\n",
    "- Evaluate the models using both the imbalanced and balanced test sets\n",
    "\n",
    "Results, smiles_one_hot.csv:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "823b067a-6276-423a-ab04-a4f00fea2461",
   "metadata": {},
   "source": [
    "                Accuracy     AUC\n",
    "Imbalanced       0.80284  0.7687\n",
    "Class-balanced   0.50948  0.7306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0809c9-9c4b-42b4-ba2d-d3898d754a1c",
   "metadata": {},
   "source": [
    "Results, diabetes_binary_health_indicators_BRFSS2015.csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6023328d-31ce-4adb-a1e6-07bcdf54b46e",
   "metadata": {},
   "source": [
    "                Accuracy     AUC\n",
    "Imbalanced        0.8128  0.8049\n",
    "class-balanced    0.5725  0.8024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2a7a7-713b-421a-8798-6288e934441c",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0693b8-3de4-4a89-94ec-e4fd0c96e4a3",
   "metadata": {},
   "source": [
    "## Code for the assignments\n",
    "Below you will find instructions for how to recreate the same simulations/tests using the same datasets, this process consists of running several python files e.g. Data preparation, modelling, testing in order to achieve the same results as the student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0d347-f59d-4089-8956-1d76ab74a050",
   "metadata": {},
   "source": [
    "### 1a\n",
    "Pre-requesites: Import the healthcare-dataset-stroke-data.csv file provided into the same directory. It should also work with any data sets with binary classification (through you must provide the correct dataset and class label in the code)\n",
    "\n",
    "Steps\n",
    "1. Run the Fx_data_preparation_A.py file to obtain two equal-sized halves of the dataset, training_set and test_set\n",
    "2. Run the Fx_RF_modelling_A.py file to find the best performing configuration of the algorithm and hyper-parameters, the output shows the parameters that will generate the best-performing model and compare with baseline model. \n",
    "    * The output also shows the amount models that perform better than the baseline model.\n",
    "3. Lastly run the Fx_RF_testing_A.py to compare the best-performing model with the baseline model, when evaluated on the second half of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4280c7e-07d6-44bb-a872-636c02123546",
   "metadata": {},
   "source": [
    "### 1b\n",
    "Pre-requesites: Import the healthcare-dataset-stroke-data.csv and smiles_one_hot.csv files provided into the same directory\n",
    "\n",
    "Steps:\n",
    "1. Run Fx_data_preparation_B1.py to obtain the training_set and test_set\n",
    "2. Run Fx_prepare_test_sets_B2.py to receive majority and equal-sized data set\n",
    "3. Run Fx_testing_B3.py to evaluate and receive the Accuracy and AUC of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea373a-d223-466f-bd98-675ba96b0971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ace91-e2e6-4acf-b261-579da8440370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
